---
title: "Marathon"
author: "Aidan Carrier"
format: pdf
---

```{python}
"""
AUTHOR: Aidan Carrier
DATE: May 13, 2025
CLASS: ISTA 421 - Machine Learning
DESCRIPTION: This file contains all of the code for a machine learning model
developed for marathon runners. This file includes every step of the process,
from the problem statement to conclusions. 
"""
```


# 1. Problem Formulation and Significance

## Problem Statement:
The Boston Marathon is one of the most prestigious marathons in the world, but marathon runners as a whole may fail to realize the significance of using machine learning methods to improve their times. 


## Significance:
Using data from a previous year, we can identify patterns and predictors of better times that could be used in helping future runners achieve faster runs.

## Dataset Description:
The data was collected from 2015, and contains 26,598 rows and 25 columns. The columns include split times every 5K, demographics such as age and gender, and overall/gender finish time. All 26,598 rows represent a runner who finished the race. 

# 2. Exploratory Data Analysis

## Data Exploration
```{python}
import pandas as pd
import numpy as np
```

```{python}
# Read in data, sometimes "-" is used instead of NA
marathon = pd.read_csv("marathon_results_2015.csv", na_values=["-"]) 
```

I noticed that a lot of columns didn’t use NA values, but instead used “-” to show empty values.

```{python}
print("Shape: ", marathon.shape)
#print("Data Types for each column: ",marathon.dtypes)
#print("NA counts: \n", marathon.isnull().sum())
```

```{python}
def time_to_sec(time):
  if pd.isna(time):
    return np.nan
  else:
    time = str(time)
    lst = time.split(":")
    return int(lst[0])*3600 + int(lst[1])*60 + int(lst[2]) 

time_cols = ['5K', '10K', '15K', '20K', 'Half', '25K',
             '30K', '35K', '40K', 'Official Time']

for col in time_cols:
  marathon[col] = marathon[col].apply(time_to_sec)
```

The values of the split times were in H:MM:SS format, and have to be converted to numeric values to be used in models.

```{python}
marathon = marathon.drop(columns=['Unnamed: 0', 'Bib', 'Name', 'City', 'State', 'Country', 'Citizen', 'Unnamed: 9', 'Division', 'Proj Time', 'Overall', 'Gender', 'Pace'])
```
Drop columns with either too many NA values, or not relevant to the problem.

```{python}
marathon.describe().T.round(1)
```
This shows the summary statistics of the numeric data. This can be used to see the means, standard deviations, and distributions of data such as min/max and percentiles. 

## Data Visualization
```{python}
import matplotlib.pyplot as plt

plt.figure()
plt.hist(marathon["Official Time"], bins=30)
plt.xlabel("Finish Time (Seconds)")
plt.ylabel("Count")
plt.title("Distribution of Finish Times")
plt.show()
```
Here is a plot of the distribution of finish times. It is interesting to see how this is right skewed. 

## Handling of Missing/Imbalanced Data 
```{python}
print("NA counts: \n", marathon.isnull().sum())
```
```{python}
marathon = marathon.dropna(subset=time_cols)
```

With over 25000 observations, we can simply remove the split times with incomplete values, without it causing too much harm to the model. It is important to note that I am dropping the whole row when removing the NA values, even if a runner only had one incomplete data point. 

```{python}
#Check
#print("NA counts: \n", marathon.isnull().sum())
```

# 3. Model Selection, Application, and Evaluation

## Justify Model Choice
Decision Trees: By classifying runners into brackets (Under 3 hours and over 5 hours) based on splits and demographic data, we can create a blueprint that future runners can use to achieve a goal. While a majority of the runners will fall into the between 3-5 hours category, they can use this model (or change the brackets) to see what they can do to improve.

## Method Applications
```{python}
def time_bracket(sec):
   if sec < (3*3600):
     return 'Under 3'
   elif sec > (5*3600):
      return 'Over 5'
   else:
      return 'Between 3–5'
    
marathon['Bracket'] = marathon['Official Time'].apply(time_bracket)

```
```{python}
# If/else statement assigning 1 to Male, 0 to Female
marathon["M/F"] =np.where(marathon["M/F"] == 'M', 1, 0)
```

```{python}
# Select features
features = ['Age', 'M/F', '5K', '15K', 'Half', '25K', '35K']
x= marathon[features]
y= marathon['Bracket']
```

```{python}
#Imports from previous time using trees, not all may be necessary
import sklearn.model_selection as skm
from ISLP.models import ModelSpec as MS
from sklearn.tree import (DecisionTreeClassifier as DTC,
                          plot_tree,
                          export_text)
from sklearn.metrics import (accuracy_score,
                             log_loss)
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier


# Get training and test data, using 20% test data 
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1000)

```

### Decision Tree

```{python}
tree = DTC(max_depth=4, random_state=1000)
tree.fit(x_train, y_train)

```
```{python}
print(export_text(tree, feature_names=features, show_weights=True))
```
This looks nice, but this barely uses any predictors

### Random Forest

```{python}
rf = RandomForestClassifier(n_estimators=100,max_depth=10, random_state=1000)
rf.fit(x_train, y_train)
```


## Model Evaluation

```{python}
validation = skm.ShuffleSplit(n_splits=1, test_size=200, random_state=0)

results = skm.cross_validate(tree, x, y, cv=validation)

print("Test Score:",results['test_score'])
```
```{python}
validation = skm.ShuffleSplit(n_splits=1, test_size=200, random_state=0)

results = skm.cross_validate(rf, x, y, cv=validation)

print("Test Score:",results['test_score'])
```
The decision tree is more intuitive, but slightly less accurate than the random forest. 

# 4. Results, Conclusions, and Real-World Implications

## Results Presentation

## Conclusions
